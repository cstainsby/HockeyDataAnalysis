{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable\n",
    "\n",
    "import mysklearn.myruleminer\n",
    "importlib.reload(mysklearn.myruleminer)\n",
    "from mysklearn.myruleminer import MyAssociationRuleMiner\n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyKNeighborsClassifier, MyDummyClassifier, MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import notebookutils\n",
    "importlib.reload(notebookutils)\n",
    "import notebookutils as nbutl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_standing_pytable = MyPyTable()\n",
    "league_standing_pytable.load_from_file(\"lib/nhl_leaguestandings.csv\")\n",
    "\n",
    "league_standing_pytable.remove_rows_with_missing_values()\n",
    "\n",
    "league_standing_pytable.drop_col(\"ROW\")\n",
    "league_standing_pytable.drop_col(\"RPt%\")\n",
    "league_standing_pytable.drop_col(\"OL\")\n",
    "league_standing_pytable.drop_col(\"T\")\n",
    "league_standing_pytable.drop_col(\"SEASON_TM\")\n",
    "league_standing_pytable.drop_col(\"SEASON\")\n",
    "league_standing_pytable.drop_col(\"CONFERENCE\")\n",
    "league_standing_pytable.drop_col(\"DIVISION\")\n",
    "league_standing_pytable.drop_col(\"TEAM\")\n",
    "league_standing_pytable.drop_col(\"TM\")\n",
    "league_standing_pytable.drop_col(\"PLAYOFFS\")\n",
    "\n",
    "\n",
    "\n",
    "#nbutl.discretize_ptspercent(league_standing_pytable.data, )\n",
    "\n",
    "#'GP', 'W', 'L','PTS','PTS%', 'GF', 'SRS'\n",
    "\n",
    "key = league_standing_pytable.get_key(league_standing_pytable.column_names, ['GP', 'W', 'L','PTS','PTS%', 'GF', 'GA', 'SRS', 'SOS'])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[0])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[1])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[2])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[3])\n",
    "nbutl.discretize_ptspercent(league_standing_pytable.data, key[4])\n",
    "nbutl.discretize_srs(league_standing_pytable.data, key[7])\n",
    "nbutl.discretize_sos(league_standing_pytable.data, key[8])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[5])\n",
    "nbutl.discretize_gf(league_standing_pytable.data, key[6])\n",
    "\n",
    "\n",
    "y_col_name = \"FINISH\"\n",
    "\n",
    "y = league_standing_pytable.get_column(y_col_name)\n",
    "league_standing_pytable.drop_col(y_col_name)\n",
    "X = [league_standing_pytable.data[i] for i in range(len(league_standing_pytable.data))]\n",
    "\n",
    "\n",
    "X_train_folds, X_test_folds  = myevaluation.stratified_kfold_cross_validation(X, y, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "DESCISION TREE\n",
      "===========================================\n",
      "Descision Tree Classifier\n",
      "     Accuracy = 0.496, Error Rate = 0.504\n",
      "     Precision = 0.346\n",
      "     Recall = 0.463\n",
      "     F1 Score = 0.396\n",
      "     Confusion Matrix\n",
      "  Outcome    0    1    2    3    4    5    Total    Recognition(%)\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ----------------\n",
      "        0  429   74    2    2    0    1      508              84.4\n",
      "        1   86  223    2   11    0    2      324              68.8\n",
      "        2   46  146    1    9    0    4      206               0.5\n",
      "        3   41   98    4   10    0    3      156               6.4\n",
      "        4   13   54    0    8    0    3       78               0\n",
      "        5    8   49    4    9    0    8       78              10.3\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "# descision tree\n",
    "\n",
    "#['GP','W','L','PTS','PTS%','GF','GA','SOS']\n",
    "\n",
    "print(\"===========================================\")\n",
    "print(\"DESCISION TREE\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "true_tr_strat, pred_tr_strat = notebookutils.kfoldstrat(league_standing_pytable, X, y, \"tree\",['GP','W','L','PTS','PTS%','GF','GA','SRS','SOS'])\n",
    "\n",
    "tr_accuracy_strat = myevaluation.accuracy_score(true_tr_strat, pred_tr_strat)\n",
    "\n",
    "print(\"Descision Tree Classifier\")\n",
    "print(\"     Accuracy = \" + str(round(tr_accuracy_strat,3)) + \", Error Rate = \" + str(round(1-tr_accuracy_strat,3)))\n",
    "print(\"     Precision = \" + str(round(myevaluation.binary_precision_score(true_tr_strat,pred_tr_strat),3)))\n",
    "print(\"     Recall = \" + str(round(myevaluation.binary_recall_score(true_tr_strat,pred_tr_strat),3)))\n",
    "print(\"     F1 Score = \" + str(round(myevaluation.binary_f1_score(true_tr_strat,pred_tr_strat),3)))\n",
    "print(\"     Confusion Matrix\\n\" + tabulate(notebookutils.matrix(true_tr_strat, pred_tr_strat), headers=[\"Outcome\",\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"Total\", \"Recognition(%)\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "NAIVE BAYES\n",
      "===========================================\n",
      "Naive Bayes Classifier\n",
      "     Accuracy = 0.521, Error Rate = 0.479\n",
      "     Precision = 0.41\n",
      "     Recall = 0.313\n",
      "     F1 Score = 0.355\n",
      "     Confusion Matrix\n",
      "  Outcome    0    1    2    3    4    5    Total    Recognition(%)\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ----------------\n",
      "        0  424   73    4    3    3    1      508              83.5\n",
      "        1   63  178   38   15    5   25      324              54.9\n",
      "        2   33  101   33    9    5   25      206              16\n",
      "        3   28   45   16   22   15   30      156              14.1\n",
      "        4    9   20    8   11   16   14       78              20.5\n",
      "        5    1   17   11   17    2   30       78              38.5\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"NAIVE BAYES\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "\n",
    "true_nb_strat, pred_nb_strat = notebookutils.kfoldstrat(league_standing_pytable, X, y, \"naive\",['GP','W','L','PTS','PTS%','GF','GA','SRS','SOS'])\n",
    "\n",
    "\n",
    "nb_accuracy_strat = myevaluation.accuracy_score(true_nb_strat, pred_nb_strat)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes Classifier\")\n",
    "print(\"     Accuracy = \" + str(round(nb_accuracy_strat,3)) + \", Error Rate = \" + str(round(1-nb_accuracy_strat,3)))\n",
    "print(\"     Precision = \" + str(round(myevaluation.binary_precision_score(true_nb_strat,pred_nb_strat),3)))\n",
    "print(\"     Recall = \" + str(round(myevaluation.binary_recall_score(true_nb_strat,pred_nb_strat),3)))\n",
    "print(\"     F1 Score = \" + str(round(myevaluation.binary_f1_score(true_nb_strat,pred_nb_strat),3)))\n",
    "print(\"     Confusion Matrix\\n\" + tabulate(notebookutils.matrix(true_nb_strat, pred_nb_strat), headers=[\"Outcome\",\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"Total\", \"Recognition(%)\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "kNN CLASSIFIER\n",
      "===========================================\n",
      "k Nearest Neighbors Classifier\n",
      "     Accuracy = 0.243, Error Rate = 0.757\n",
      "     Precision = 0.239\n",
      "     Recall = 0.988\n",
      "     F1 Score = 0.385\n",
      "     Confusion Matrix\n",
      "  Outcome    0    1    2    3    4    5    Total    Recognition(%)\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ----------------\n",
      "        0    8  500    0    0    0    0      508               1.6\n",
      "        1    3  320    1    0    0    0      324              98.8\n",
      "        2    0  206    0    0    0    0      206               0\n",
      "        3    0  156    0    0    0    0      156               0\n",
      "        4    0   78    0    0    0    0       78               0\n",
      "        5    0   78    0    0    0    0       78               0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"kNN CLASSIFIER\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "\n",
    "true_knn_strat, pred_knn_strat = notebookutils.kfoldstrat(league_standing_pytable, X, y, \"knn\",['GP','W','L','PTS','PTS%','GF','GA','SRS','SOS'])\n",
    "\n",
    "knn_accuracy_strat = myevaluation.accuracy_score(true_knn_strat, pred_knn_strat)\n",
    "\n",
    "\n",
    "print(\"k Nearest Neighbors Classifier\")\n",
    "print(\"     Accuracy = \" + str(round(knn_accuracy_strat,3)) + \", Error Rate = \" + str(round(1-knn_accuracy_strat,3)))\n",
    "print(\"     Precision = \" + str(round(myevaluation.binary_precision_score(true_knn_strat,pred_knn_strat),3)))\n",
    "print(\"     Recall = \" + str(round(myevaluation.binary_recall_score(true_knn_strat,pred_knn_strat),3)))\n",
    "print(\"     F1 Score = \" + str(round(myevaluation.binary_f1_score(true_knn_strat,pred_knn_strat),3)))\n",
    "print(\"     Confusion Matrix\\n\" + tabulate(notebookutils.matrix(true_knn_strat, pred_knn_strat), headers=[\"Outcome\",\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"Total\", \"Recognition(%)\"]))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "Rule Miner\n",
      "===========================================\n",
      "Rule Table\n",
      "  #  RULE                 SUPPORT    CONFIDENCE      LIFT\n",
      "---  -----------------  ---------  ------------  --------\n",
      "  1  IF 4 THEN 5        0.0644444      0.517857  1.60346\n",
      "  2  IF 4 THEN 7        0.101481       0.815476  1.01092\n",
      "  3  IF 6 THEN 5        0.211852       0.276329  0.855604\n",
      "  4  IF 5 THEN 6        0.211852       0.655963  0.855604\n",
      "  5  IF 7 THEN 5        0.245926       0.304867  0.943968\n",
      "  6  IF 5 THEN 7        0.245926       0.761468  0.943968\n",
      "  7  IF 7 THEN 6        0.573333       0.710744  0.927057\n",
      "  8  IF 6 THEN 7        0.573333       0.747826  0.927057\n",
      "  9  IF 8 THEN 6        0.131111       0.783186  1.02155\n",
      " 10  IF 8 THEN 7        0.121481       0.725664  0.899583\n",
      " 11  IF 5 AND 7 THEN 4  0.0548148      0.222892  1.79109\n",
      " 12  IF 4 AND 7 THEN 5  0.0548148      0.540146  1.67247\n",
      " 13  IF 4 AND 5 THEN 7  0.0548148      0.850575  1.05443\n",
      " 14  IF 4 THEN 5 AND 7  0.0548148      0.440476  1.79109\n",
      " 15  IF 6 AND 7 THEN 5  0.134815       0.235142  0.728078\n",
      " 16  IF 5 AND 7 THEN 6  0.134815       0.548193  0.715034\n",
      " 17  IF 5 AND 6 THEN 7  0.134815       0.636364  0.788881\n",
      " 18  IF 5 THEN 6 AND 7  0.134815       0.417431  0.728078\n",
      " 19  IF 7 AND 8 THEN 6  0.0851852      0.70122   0.914634\n",
      " 20  IF 6 AND 8 THEN 7  0.0851852      0.649718  0.805435\n",
      " 21  IF 8 THEN 6 AND 7  0.0851852      0.50885   0.887528\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"Rule Miner\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "rule_miner = MyAssociationRuleMiner(minsup=0.05, minconf=.2)\n",
    "rule_miner.fit(league_standing_pytable.data)\n",
    "rule_miner.print_association_rules()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "RANDOM FOREST CLASSIFIER\n",
      "===========================================\n",
      "Random Forest Classifier\n",
      "     Accuracy = 0.5, Error Rate = 0.5\n",
      "     Precision = 0.344\n",
      "     Recall = 0.443\n",
      "     F1 Score = 0.387\n",
      "     Confusion Matrix\n",
      "  Outcome    0    1    2    3    4    5    Total    Recognition(%)\n",
      "---------  ---  ---  ---  ---  ---  ---  -------  ----------------\n",
      "        0  433   69    4    0    1    1      508              85.2\n",
      "        1   88  213   15    7    0    1      324              65.7\n",
      "        2   43  137   15   11    0    0      206               7.3\n",
      "        3   30   98   13   11    2    2      156               7.1\n",
      "        4   10   53    7    6    1    1       78               1.3\n",
      "        5    5   50   11    9    0    3       78               3.8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"===========================================\")\n",
    "print(\"RANDOM FOREST CLASSIFIER\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "\n",
    "true_rand_forest_strat, pred_rand_forest_strat = notebookutils.kfoldstrat(league_standing_pytable, X, y, \"rand_forest\",['GP','W','L','PTS','PTS%','GF','GA','SRS','SOS'])\n",
    "\n",
    "rand_forest_accuracy_strat = myevaluation.accuracy_score(true_rand_forest_strat, pred_rand_forest_strat)\n",
    "\n",
    "\n",
    "print(\"Random Forest Classifier\")\n",
    "print(\"     Accuracy = \" + str(round(rand_forest_accuracy_strat,3)) + \", Error Rate = \" + str(round(1-rand_forest_accuracy_strat,3)))\n",
    "print(\"     Precision = \" + str(round(myevaluation.binary_precision_score(true_rand_forest_strat,pred_rand_forest_strat),3)))\n",
    "print(\"     Recall = \" + str(round(myevaluation.binary_recall_score(true_rand_forest_strat,pred_rand_forest_strat),3)))\n",
    "print(\"     F1 Score = \" + str(round(myevaluation.binary_f1_score(true_rand_forest_strat,pred_rand_forest_strat),3)))\n",
    "print(\"     Confusion Matrix\\n\" + tabulate(notebookutils.matrix(true_rand_forest_strat, pred_rand_forest_strat), headers=[\"Outcome\",\"0\",\"1\", \"2\", \"3\", \"4\", \"5\", \"Total\", \"Recognition(%)\"]))\n",
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
